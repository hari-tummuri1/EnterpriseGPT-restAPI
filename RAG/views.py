from django.shortcuts import render
from rest_framework import status, generics
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework.decorators import api_view
from RAG.serializers import EnterpriseDocumentSerializer,UserSerializer, ConversationSerializer, MessageSerializer, UserDocumentSerializer, RephrasedQuestionsSerializer, EnterpriseDictionarySerializer, SystemPromptSerializer, LLMTemperatureSerializer, LLMSerializer, ContentFilterSerializer
from .models import EnterpriseDocuments,Users, Conversation, Message, UserDocuments, EnterpriseDictionary, SystemPrompt, LLMTemperature, LLM, ContentFilters
from django.db.models import Count  
from django.db.models.functions import TruncDate  
from collections import defaultdict 
from .anonymization import anonymize, deAnonymize
from django.http import StreamingHttpResponse
from django.views.decorators.csrf import csrf_exempt
from django.conf import settings  
  

# from .models import Conversation, Message
# from .serializers import ConversationSerializer, MessageSerializer

import os
import openai
# from dotenv import load_dotenv
from langchain.chat_models import AzureChatOpenAI
from langchain.embeddings import AzureOpenAIEmbeddings
from langchain.vectorstores import AzureSearch
# from langchain.document_loaders import DirectoryLoader
from langchain_community.document_loaders import DirectoryLoader
# from langchain.document_loaders import PyPDFLoader
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import TokenTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from django.core.files.storage import FileSystemStorage
from azure.core.credentials import AzureKeyCredential
from azure.search.documents.indexes import SearchIndexClient
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

response_from = ""
# Create your views here.
@api_view(['POST'])
def RagResponse(request):
    
    query = request.data.get('query', None)
    conv_id = request.data.get('conv_id', None)

    if query is None:  
        return Response({'error': 'No query provided'}, status=status.HTTP_400_BAD_REQUEST)
    elif conv_id is None:
         return Response({'error': 'No conversation id provided'}, status=status.HTTP_400_BAD_REQUEST)
    # print(query)
    # print(conv_id)

    # replacement_dict = {  
    #         "Zscaler": "VPN",  
    #         "myWipro": "Intranet"    
    #         # Add other words here    
    #     } 
    
    result = replace_words(query)
    print ("rePhrased Prompt :"+ result[0])
    replaced = ""
    ewords = ""
    if result[0] != query:
        words = result[1]
        replaced_words = result[2]
        for i in range(len(words)):
            if words[i] == replaced_words[i]:
                continue
            else:
                # ewords.append(words[i])
                # replaced.append(replaced_words[i])
                if i == len(words)-1:
                    replaced += "**"+replaced_words[i]+"** "
                    ewords += "**"+words[i]+"** "
                else:
                    replaced += "**"+replaced_words[i]+"** , "
                    ewords += "**"+words[i]+"** , "
    if replaced.endswith(", "):  
        replaced = replaced[:-2]  # remove the last 2 characters
    if ewords.endswith(", "):  
        ewords = ewords[:-2]  # remove the last 2 characters

    result = result[0]
    q_dict = {
        "original_query" : query,
        "rephrased_query" : result
    }


    serializer2 = RephrasedQuestionsSerializer(data=q_dict)
    if serializer2.is_valid():
        serializer2.save()
        # return Response(serializer2.data, status=status.HTTP_201_CREATED)

    userMsg = {
         'msg' : result,
         'conv_id' : conv_id,
         'msg_type' : "user"
    }
    # print(userMsg)
    userserializer = MessageSerializer(data=userMsg)
    print(userserializer)
    

    # anonymized_prompt = anonymize(result)
    # print(anonymized_prompt)

    # answer = StreamingHttpResponse(process_query(anonymized_prompt, conv_id))
    # answer['Content-Type'] = 'text/plain'
    global response_from
    if find_substring(result, "Wipro policy"):
        # pass
        print("Fetching from enterprise knowledge")
        answer = process_query(result, conv_id, "e-gpt") 
        response_from =  "This response is generated using Wipro internal documents"
    else:
        print("Fetching from LLM")
        answer = llmCall(result, conv_id)
        # response_from = "This response is generated by Enterprise dictionary assistance"
    if response_from == "This response is generated by Enterprise dictionary assistance":
        note = "Your query consists of enterprise word(s) "+ewords+". Replacing with "+replaced+ " for better response"
        answer = note+"\n\n"+answer
    print("response : " +answer)
    # answer = deAnonymize(answer)
    print("response from : "+ response_from)

    count = Message.objects.filter(conv_id=conv_id).count()
    if count == 0:
        try:
            conversation = Conversation.objects.get(id=conv_id)
        except Conversation.DoesNotExist:
            return Response(status=status.HTTP_404_NOT_FOUND)
        
        cdata = {
            'conv_name' : result
        }
        convserializer = ConversationSerializer(conversation, data=cdata, partial=True)
        if convserializer.is_valid():
            convserializer.save()
            print("conv name changed to :" + result)

    if userserializer.is_valid():
        userserializer.save()
    else:
         print('Not valid question')

    botMsg = {
        'msg' : answer,
        'conv_id' : conv_id,
        'msg_type' : "assistant",
        'response_from' : response_from
    }

    botSerializer = MessageSerializer(data = botMsg)
    if botSerializer.is_valid():
        botSerializer.save()
        return Response(botSerializer.data, status=status.HTTP_201_CREATED)
        
    return Response(botSerializer.error_messages, status=status.HTTP_400_BAD_REQUEST)
    # return answer
    # Return the answer  
    # return Response({'answer': answer}) 

def process_query(query, conv_id, index):
    OPENAI_API_BASE = "https://dwspoc.openai.azure.com/"
    OPENAI_API_KEY = settings.OPENAI_API_KEY
    print("api key" + str(OPENAI_API_KEY))
    OPENAI_API_VERSION = "2024-02-15-preview"
    AZURE_COGNITIVE_SEARCH_SERVICE_NAME = 'enterprisegptaisearch'
    # AZURE_COGNITIVE_SEARCH_INDEX_NAME = "e-gpt"
    AZURE_COGNITIVE_SEARCH_INDEX_NAME = index
    vector_store_address= "https://enterprisegptaisearch.search.windows.net"
    vector_store_password= settings.AZURE_COGNITIVE_SEARCH_API_KEY

    openai.api_type = "azure"
    openai.base_url = OPENAI_API_BASE
    openai.api_key = OPENAI_API_KEY
    openai.api_version = OPENAI_API_VERSION

    conversations = Message.objects.filter(conv_id = conv_id)
    serializer = MessageSerializer(conversations, many=True)
    print(serializer.data)
    context=""
    # for obj in serializer.data[-6:]:  
    #     # get the msg_type and msg  
    #     msg_type = obj.get('msg_type')  
    #     msg = obj.get('msg')  
        
    #     # add the msg_type and msg to the string  
    #     context += f"{msg_type}: {msg}" 



    #initializing LLMs 

    llm = AzureChatOpenAI(deployment_name="GPT4", openai_api_key=OPENAI_API_KEY, openai_api_base=OPENAI_API_BASE, openai_api_version=OPENAI_API_VERSION,streaming=True, callbacks=[StreamingStdOutCallbackHandler()])
    # embeddings = AzureOpenAIEmbeddings(azure_deployment="text-embedding-ada-002", chunk_size=500, openai_api_key=OPENAI_API_KEY, openai_api_base=OPENAI_API_BASE, openai_api_version=OPENAI_API_VERSION)
    embeddings = AzureOpenAIEmbeddings(
        azure_deployment="text-embedding-ada-002",
        openai_api_version="2023-05-15",
        azure_endpoint=OPENAI_API_BASE,
        api_key= OPENAI_API_KEY)
    
    #connect to azure cognitive search
    acs = AzureSearch(azure_search_endpoint=vector_store_address, azure_search_key=vector_store_password, index_name=AZURE_COGNITIVE_SEARCH_INDEX_NAME, embedding_function=embeddings.embed_query)

    CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template("""Given the following conversation and a follow up question, rephrase the follow up question to be standalone question. if the provided context does not have information, then say relevant information not found

    Chat history:
    {chat_history}
    Follow up input: {question}
    Standalone question:""")

    qa = ConversationalRetrievalChain.from_llm(llm=llm,
                                                retriever=acs.as_retriever(),
                                                condense_question_prompt=CONDENSE_QUESTION_PROMPT,
                                                return_source_documents=True,
                                                verbose=False
                                                )
    
    chat_history = []
    question = 'Answer the following question using the provided context and chat history only, give least priority to chat history. If the provided context and chat history does not have any information about it then say "provided context does not have information about it". Chat history is'+context+' Query : '+query+'generate complete response in 10 seconds'

    print("searching in index "+index)
    result = qa({"question": question, "chat_history": chat_history})
    # for i in qa({"question": question, "chat_history": chat_history}):
    #     yield f"Data chunk {i}\n"
    # print("Question:", query)
    # print("answer:", result["answer"])

    return result['answer']

def find_substring(main_string, substring):  
    # Convert both strings to lower case  
    main_string_lower = main_string.lower()  
    substring_lower = substring.lower()  
  
    # Check if the lower-cased substring is in the lower-cased main string  
    if substring_lower in main_string_lower:  
        return True  
    else:  
        return False

def llmCall(query,conv_id):
    import json
    import requests  

    try:  
        person = SystemPrompt.objects.get(pk=1) 
    except SystemPrompt.DoesNotExist:
        return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = SystemPromptSerializer(person)
    system_prompt = serializer.data["prompt"] + "If the user question contains PII (Personal Identifiable Information) or confidential information like salary and financial related, then dont process the question instead say 'Sorry! this contains Personal Identifiable Information, i cant process this information' and give what is that Personal Identifiable Information. If the users asks for their previous question, if their previous questions contains PII (Personal Identifiable Information) or confidential information like salary and financial related then give the response saying Sorry! this contains Personal Identifiable Information, i cant process this information' and give what is that Personal Identifiable Information."

    try:
        temperature = LLMTemperature.objects.get(pk=1)
    except LLMTemperature.DoesNotExist:
        return Response(status=status.HTTP_404_NOT_FOUND) 
    
    tempSerializer = LLMTemperatureSerializer(temperature)
    temperature = float(tempSerializer.data["temperature"])
    # print("temperature : "+ temperature)
    print(type(temperature))
    conversations = Message.objects.filter(conv_id = conv_id)
    messageSerializer = MessageSerializer(conversations, many=True)
    system_prompt = {"role":"system","content":system_prompt}
    query = {"role":"user", "content": query}
    context = [{"role": item["msg_type"], "content": item["msg"]} for item in messageSerializer.data[-6:]] 
    context.insert(0, system_prompt)
    context.append(query) 
    # testdata = {
    #     "messages": [  
    #             {"role":"system","content":system_prompt},  
    #             str(context),  
    #             {"role":"assistant","content":"Hello! How can I assist you today?"}  ,
    #         ]
    # }
    # print("testdata" + str(testdata))
    print("Context : "+str(context))
    # print("api key :"+str(settings.OPENAI_API_KEY))
    url = "https://dwspoc.openai.azure.com/openai/deployments/GPT4/chat/completions?api-version=2024-02-15-preview"  
    headers = {  
        "Content-Type": "application/json",  
        "api-key": settings.OPENAI_API_KEY
    }

    data = {  
            "messages": context,  
            "max_tokens": 800,  
            "temperature": temperature,  
            "frequency_penalty": 0,  
            "presence_penalty": 0,  
            "top_p": 0.95,  
            "stop": None  
        }

    response = requests.post(url, headers=headers, data=json.dumps(data))
    print("this is the llm response : "+str(response.json))
    return response.json()['choices'][0]['message']['content']
def replace_words(sentence):  
    global response_from
    # words = sentence.split()  
    words = sentence.lower().split()  
    e_words = EnterpriseDictionary.objects.all()
    e_words = EnterpriseDictionarySerializer(e_words, many=True)
    # print(e_words.data)
    e_words = {item['original_word']: item['enterprise_word'] for item in e_words.data}
    # replacement_dict_lower = {key.lower(): value for key, value in e_words.items()} 
    e_words = {k.lower(): v for k, v in e_words.items()} 
    print(e_words)
    replaced_words = [e_words.get(word, word) for word in words]  
    # replaced_words = [replacement_dict[replacement_dict_lower.get(word.lower(), word)] for word in words] 
    replaced_sentence = ' '.join(replaced_words).capitalize()
    if replaced_sentence.lower() == str(sentence).lower():
        response_from = "This response is generated by AI model"
    else:
        response_from = "This response is generated by Enterprise dictionary assistance"
    return [replaced_sentence, words, replaced_words] 

@api_view(['POST'])
def addEnterpriseWord(request):
    serializer = EnterpriseDictionarySerializer(data=request.data)
    if serializer.is_valid():
        # original_word = serializer.validated_data.get('original_word').lower() 
        original_word = serializer.validated_data.get('original_word')  
        original_word = original_word.lower() if original_word else original_word  
        enterprise_word = serializer.validated_data.get('enterprise_word')  
        obj, created = EnterpriseDictionary.objects.get_or_create(  
            original_word__iexact=original_word,  
            defaults={'enterprise_word': enterprise_word, 'original_word': original_word},  
        )

        if not created and obj.enterprise_word != enterprise_word: 
            # obj.original_word = original_word
            obj.enterprise_word = enterprise_word  
            obj.save()
        
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def getAllEnterpriseWords(request):
    words = EnterpriseDictionary.objects.all()
    serializer = EnterpriseDictionarySerializer(words, many=True)
    return Response(serializer.data)

@api_view(['POST'])
def updateEnterpriseWords(request, id):
    try:
        word = EnterpriseDictionary.objects.get(id=id)

    except EnterpriseDictionary.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = EnterpriseDictionarySerializer(word, data=request.data, partial=True)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_200_OK)
    return Response(status=status.HTTP_400_BAD_REQUEST)

@api_view(['DELETE'])
def deleteEnterpriseWord(request, id):
    try:
         word = EnterpriseDictionary.objects.get(pk=id) 
    except EnterpriseDictionary.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)
    
    #deleting the word
    word.delete()
    return Response({'message': 'Enterprise word deleted successfully'},status=status.HTTP_204_NO_CONTENT)

@api_view(['POST'])
def getChatmsgs(request, conv_id):
    msgs = Message.objects.filter(conv_id=conv_id)
    serializer = MessageSerializer(msgs, many=True)
    return Response(serializer.data, status=status.HTTP_202_ACCEPTED)

@api_view(['POST'])
def updateMsg(request, id):
    try:
        message = Message.objects.get(id=id)

    except Message.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)

    if request.method == 'POST':
        serializer = MessageSerializer(message, data=request.data, partial=True)
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data, status=status.HTTP_200_OK)
        return Response(status=status.HTTP_400_BAD_REQUEST)


    
@api_view(['POST'])
def DocumentUploadView(request):
    if 'document' not in request.FILES:  
            return Response({'error': 'No document in request.'}, status=status.HTTP_400_BAD_REQUEST) 
        
    document = request.FILES['document']  
    fs = FileSystemStorage(location= r'RAG\EnterpriseDocs\\')  
    filename = fs.save(document.name, document) 
    path = r'RAG\EnterpriseDocs\\' + filename
    docdata = {
         "edoc_path" : path
    }
   
    print(path)


    file_path = fs.path(filename) 
    print(file_path) 
    index_name = 'e-gpt'
    if processDocument(file_path,index_name) == 'Document added':
        serializer = EnterpriseDocumentSerializer(data = docdata)
        if serializer.is_valid():
             serializer.save()
        else:
             print('not a valid data')
        return Response(serializer.data, status=status.HTTP_200_OK)
    
def processDocument(filepath, index_name):
        OPENAI_API_BASE = "https://dwspoc.openai.azure.com/"
        OPENAI_API_KEY = settings.OPENAI_API_KEY
        OPENAI_API_VERSION = "2024-02-15-preview"
        AZURE_COGNITIVE_SEARCH_SERVICE_NAME = 'enterprisegptaisearch'
        AZURE_COGNITIVE_SEARCH_INDEX_NAME = index_name
        vector_store_address= "https://enterprisegptaisearch.search.windows.net"
        vector_store_password= settings.AZURE_COGNITIVE_SEARCH_API_KEY

        openai.api_type = "azure"
        openai.base_url = OPENAI_API_BASE
        openai.api_key = OPENAI_API_KEY
        openai.api_version = OPENAI_API_VERSION

        embeddings = AzureOpenAIEmbeddings(
                        azure_deployment="text-embedding-ada-002",
                        openai_api_version="2023-05-15",
                        azure_endpoint=OPENAI_API_BASE,
                        api_key= OPENAI_API_KEY
                    )
        
        #Connecting to azure cognitive search
        acs = AzureSearch(azure_search_endpoint=vector_store_address, azure_search_key=vector_store_password, index_name=AZURE_COGNITIVE_SEARCH_INDEX_NAME, embedding_function=embeddings.embed_query)
        
        loader = PyPDFLoader(filepath)
        document = loader.load()
        text_splitter = TokenTextSplitter(chunk_size=250, chunk_overlap=20)
        docs = text_splitter.split_documents(document)
        acs.add_documents(documents=docs)
        return 'Document added'


@api_view(['DELETE'])
def deleteDocument(request, id):
    try:
         document = EnterpriseDocuments.objects.get(pk=id) 
    except EnterpriseDocuments.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)
    serializer = EnterpriseDocumentSerializer(document)
    filepath = serializer.data['edoc_path']

    # Deleting file in filesystem

    print(filepath)
    if os.path.exists(filepath):  
        os.remove(filepath)  
        print("File deleted.")  
    else:  
        return Response(status=status.HTTP_404_NOT_FOUND)  
    
    #deleting the file path in database
    document.delete()

    #Updating the vector store
    endpoint = "https://enterprisegptaisearch.search.windows.net"
    admin_key = settings.AZURE_COGNITIVE_SEARCH_API_KEY 
    index_name = "e-gpt"
    credential = AzureKeyCredential(admin_key)  
    client = SearchIndexClient(endpoint, AzureKeyCredential(admin_key))
    client.delete_index(index_name)  

    pre_path = r'RAG\EnterpriseDocs\\'
    documents = []
    pdf_files = [f for f in os.listdir(pre_path) if f.endswith(".pdf")]  
    print(pdf_files)
    for i in pdf_files:
        processDocument(pre_path+i, index_name)
    
    return Response(status=status.HTTP_204_NO_CONTENT)

@api_view(['DELETE'])
def delete_all_enterprisedocs(request):
    from azure.core.credentials import AzureKeyCredential  
    # from azure.search.documents import SearchIndexClient  
    from azure.search.documents.indexes import SearchIndexClient

    if request.method == 'DELETE':  
        count = EnterpriseDocuments.objects.all().delete()

        folder_path = r'RAG\EnterpriseDocs\\'
  
        for filename in os.listdir(folder_path):  
            if filename.endswith('.pdf'):  
                os.remove(os.path.join(folder_path, filename)) 

        endpoint = "https://enterprisegptaisearch.search.windows.net"
        admin_key = settings.AZURE_COGNITIVE_SEARCH_API_KEY 
        index_name = "e-gpt"  
        # index_name = 'user-docs'
  
        credential = AzureKeyCredential(admin_key)  
        client = SearchIndexClient(endpoint, AzureKeyCredential(admin_key))
        
        client.delete_index(index_name)
        return Response(status=status.HTTP_204_NO_CONTENT)
    
             
@api_view(['GET', 'POST'])             
def UserDetails(request):
     if request.method == 'GET':
        users = Users.objects.all()
        serializer = UserSerializer(users, many=True)
        return Response(serializer.data)
     elif request.method == 'POST':
          serializer = UserSerializer(data=request.data)
          if serializer.is_valid():
               serializer.save()
               return Response(serializer.data, status=status.HTTP_201_CREATED)
          return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) 
     
@api_view(['POST'])     
def ConvDetails(request):
    if request.method == 'POST':
        email_id = request.data.get('email_id', None)
        print(email_id)
        data = {
            'email_id' : email_id,
            'conv_name' : 'New Conversation'
        }
        serializer = ConversationSerializer(data=data)
        if serializer.is_valid():
            serializer.save()
            #conversation = Conversation.objects.get(email_id=email_id)
            return Response(serializer.data, status=status.HTTP_201_CREATED) 
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
    
@csrf_exempt
@api_view(['POST'])
def getAllUserConv(request,email):
    if request.method == 'POST':
        conversations = Conversation.objects.filter(email_id = email)
        serializer = ConversationSerializer(conversations, many=True)
        print("initial conversations "+str(len(serializer.data)))
        # Get all conv_id from Message model
        message_ids = Message.objects.values_list('conv_id', flat=True)

        # Filter the conversations queryset to only include ids present in RagMessage  
        filtered_conversations = conversations.filter(id__in=message_ids)

        # Serialize the queryset with the new serializer  
        serializer = ConversationSerializer(filtered_conversations, many=True)
        print("final conversations "+str(len(serializer.data)))  

        return Response(serializer.data)
         

@api_view(['POST','PUT','GET','DELETE'])
def ConvDetailsPK(request, id):
    try:
        conversation = Conversation.objects.get(id=id)

    except Conversation.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)

    if request.method == 'POST':
        serializer = ConversationSerializer(conversation, data=request.data, partial=True)
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data, status=status.HTTP_200_OK)
        return Response(status=status.HTTP_400_BAD_REQUEST)
    elif request.method == 'DELETE':
        Message.objects.filter(conv_id=id).delete()  
        conversation.delete()
        return Response({'message': 'Conversation deleted successfully'},status=status.HTTP_204_NO_CONTENT)
         

@api_view(['POST'])
def userDocumetUpload(request, email_id):
    if 'document' not in request.FILES:  
            return Response({'error': 'No document in request.'}, status=status.HTTP_400_BAD_REQUEST)
    document = request.FILES['document']  
    fs = FileSystemStorage(location= r'RAG\UserDocs\\')  
    filename = fs.save(document.name, document) 
    path = r'RAG\UserDocs\\' + filename
    print(path)
    docdata = {
        'udoc_path' : path,
        'email_id' : email_id
    }

    print(docdata)

    file_path = fs.path(filename)
    # print(file_path)
    print(file_path)

    #parsing file name
    # filename = "GlobalPSHPolicy_5bjLLDt.pdf"  
    filename = filename[:-4]  # remove the last 4 characters (.pdf)  
    filename = filename.replace('_', '-')  # replace '_' with '-'  
    filename = filename.lower()  # convert to lowercase  

    #parsing email_id
    username = email_id.split('@')[0]  # split the string at '@' and get the first part   
    email_id = username.replace('.', '-')  # replace '.' with '_'  

    index_name = filename+"-"+email_id
    print("index name : "+index_name)
    # index_name = 'user-docs'
    if processDocument(file_path,index_name) == 'Document added':
        serializer = UserDocumentSerializer(data = docdata)
        if serializer.is_valid():
             serializer.save()
        else:
             print('not a valid data')
        return Response(serializer.data, status=status.HTTP_200_OK)
   
@api_view(['POST'])   
def deleteUserDoc(request, id):
    email_id = request.data.get('email_id', None)

    try:
         document = UserDocuments.objects.get(pk=id) 
    except UserDocuments.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = UserDocumentSerializer(document)
    filepath = serializer.data['udoc_path']
    filename = os.path.basename(filepath)

    #parsing file name
    # filename = "GlobalPSHPolicy_5bjLLDt.pdf"  
    filename = filename[:-4]  # remove the last 4 characters (.pdf)  
    filename = filename.replace('_', '-')  # replace '_' with '-'  
    filename = filename.lower()  # convert to lowercase  

    #parsing email_id
    username = email_id.split('@')[0]  # split the string at '@' and get the first part   
    email_id = username.replace('.', '-')  # replace '.' with '_'  

    index_name = filename+"-"+email_id
    print("index name : "+index_name)

    print(filepath)
    if os.path.exists(filepath):  
        os.remove(filepath)  
        print("File deleted.")  
    else:  
        return Response(status=status.HTTP_404_NOT_FOUND) 
    
    #deleting the file path in database
    document.delete()

    #Updating the vector store
    endpoint = "https://enterprisegptaisearch.search.windows.net"
    admin_key = settings.AZURE_COGNITIVE_SEARCH_API_KEY  
    # index_name = 'user-docs'
    credential = AzureKeyCredential(admin_key)  
    client = SearchIndexClient(endpoint, AzureKeyCredential(admin_key))
    print("deleting index " + index_name)
    client.delete_index(index_name)

    # pre_path = r'RAG\UserDocs\\'
    # documents = []
    # pdf_files = [f for f in os.listdir(pre_path) if f.endswith(".pdf")]  
    # print(pdf_files)
    # for i in pdf_files:
    #     processDocument(pre_path+i, index_name)

    return Response(status=status.HTTP_204_NO_CONTENT)

@api_view(['DELETE'])
def deleteSpecificUserDocs(request, email_id):
    # Retrieve all MyTable objects for the given email_id  
    user_docs = UserDocuments.objects.filter(email_id=email_id)
    serializer = UserDocumentSerializer(user_docs, many=True)
    folder_path = r'RAG\UserDocs\\'
    # Extract filenames and store in a list  
    filenames = [os.path.basename(item["udoc_path"]) for item in serializer.data]

    for item in serializer.data:
        file_path = os.path.join(folder_path, os.path.basename(item["udoc_path"]))
        try:  
            os.remove(file_path)  
            print(f"File {file_path} has been deleted")  
        except FileNotFoundError:  
            print(f"File {file_path} not found")
    
    index_name=[]
    for item in serializer.data:
        filename = item['udoc_path']
        email_id = item['email_id']

        filename = os.path.basename(filename)
        #parsing filename
        filename = filename[:-4]  # remove the last 4 characters (.pdf)  
        filename = filename.replace('_', '-')  # replace '_' with '-'  
        filename = filename.lower()  # convert to lowercase  
        #parsing email_id
        username = email_id.split('@')[0]  # split the string at '@' and get the first part   
        email_id = username.replace('.', '-')  # replace '.' with '_'  
        index = filename+"-"+email_id
        index_name.append(index)
    print(index_name)
    endpoint = "https://enterprisegptaisearch.search.windows.net"
    admin_key = settings.AZURE_COGNITIVE_SEARCH_API_KEY
    credential = AzureKeyCredential(admin_key)  
    client = SearchIndexClient(endpoint, AzureKeyCredential(admin_key))

    for index in index_name:
        print("deleting vectorstore "+index)
        client.delete_index(index)

    # Delete the records  
    for doc in user_docs:  
        doc.delete() 
    
    print(deleteAllUserConvs(email_id=email_id))

    return Response({'message':'Deleted all data related to '+email_id})



    
@api_view(['DELETE'])
def deleteAllUserDocs(request):
    # from azure.core.credentials import AzureKeyCredential  
    # # from azure.search.documents import SearchIndexClient  
    # from azure.search.documents.indexes import SearchIndexClient

    if request.method == 'DELETE':
        documents = UserDocuments.objects.all() 
        document_serializer = UserDocumentSerializer(documents, many=True)

        folder_path = r'RAG\UserDocs\\'
  
        for filename in os.listdir(folder_path):  
            if filename.endswith('.pdf'):  
                os.remove(os.path.join(folder_path, filename)) 

        index_name=[]
        for item in document_serializer.data:
            filename = item['udoc_path']
            email_id = item['email_id']

            filename = os.path.basename(filename)
            #parsing filename
            filename = filename[:-4]  # remove the last 4 characters (.pdf)  
            filename = filename.replace('_', '-')  # replace '_' with '-'  
            filename = filename.lower()  # convert to lowercase  
            #parsing email_id
            username = email_id.split('@')[0]  # split the string at '@' and get the first part   
            email_id = username.replace('.', '-')  # replace '.' with '_'  
            index = filename+"-"+email_id
            index_name.append(index) 

        print(index_name)
        endpoint = "https://enterprisegptaisearch.search.windows.net"
        admin_key = settings.AZURE_COGNITIVE_SEARCH_API_KEY 
        # index_name = "e-gpt"  
        # index_name = 'user-docs'
  
        credential = AzureKeyCredential(admin_key)  
        client = SearchIndexClient(endpoint, AzureKeyCredential(admin_key))
        for index in index_name:
            print("deleting vectorstore "+index)
            client.delete_index(index)
        count = UserDocuments.objects.all().delete()
        return Response(status=status.HTTP_204_NO_CONTENT)
@api_view(['POST'])
def getUserDocs(request):
    email_id = request.data.get('email_id', None)
    documents = UserDocuments.objects.filter(email_id = email_id)
    serializer = UserDocumentSerializer(documents, many = True)
    # Modify the data to only include the filename  
    for item in serializer.data:  
        item['udoc_path'] = os.path.basename(item['udoc_path'])
    return Response(serializer.data)

@api_view(['POST'])
def userDocResponse(request):
    query = request.data.get('query', None)
    filename = request.data.get('filename', None)
    conv_id = request.data.get('conv_id', None)

    if query is None:  
        return Response({'error': 'No query provided'}, status=status.HTTP_400_BAD_REQUEST)
    elif conv_id is None:
         return Response({'error': 'No conversation id provided'}, status=status.HTTP_400_BAD_REQUEST)
    elif filename is None:
         return Response({'error': 'No filename provided'}, status=status.HTTP_400_BAD_REQUEST)
    # email_id = ""
    try:  
        conversation = Conversation.objects.get(pk=conv_id)  
        # email_id = conversation.email_id
        # return Response({'email_id': conversation.email_id})  
    except Conversation.DoesNotExist:  
        return Response({'error': 'Conversation not found'}, status=404)
    conv_serializer = ConversationSerializer(conversation)
    email_id = conv_serializer.data['email_id']
    
     #parsing file name
    # filename = "GlobalPSHPolicy_5bjLLDt.pdf" 
    filename2 = filename
    filename = filename[:-4]  # remove the last 4 characters (.pdf)  
    filename = filename.replace('_', '-')  # replace '_' with '-'  
    filename = filename.lower()  # convert to lowercase  

    #parsing email_id
    username = email_id.split('@')[0]  # split the string at '@' and get the first part   
    email_id = username.replace('.', '-')  # replace '.' with '_'  

    index_name = filename+"-"+email_id
    print("index name : "+index_name)
    userMsg = {
         'msg' : query,
         'conv_id' : conv_id,
         'msg_type' : "user"
    }
    # print(userMsg)
    userserializer = MessageSerializer(data=userMsg)
    print(userserializer)

    # anonymized_prompt = anonymize(query)
    # print(anonymized_prompt)

    # answer = StreamingHttpResponse(process_query(anonymized_prompt, conv_id))
    # answer['Content-Type'] = 'text/plain'
    answer = process_query(query, conv_id, index_name)
    # answer = deAnonymize(answer)
    print(answer)

    count = Message.objects.filter(conv_id=conv_id).count()
    if count == 0:
        try:
            conversation = Conversation.objects.get(id=conv_id)
        except Conversation.DoesNotExist:
            return Response(status=status.HTTP_404_NOT_FOUND)
        
        cdata = {
            'conv_name' : query
        }
        convserializer = ConversationSerializer(conversation, data=cdata, partial=True)
        if convserializer.is_valid():
            convserializer.save()
            print("conv name changed to :" + query)


    if userserializer.is_valid():
        userserializer.save()
    else:
         print('Not valid question')

    botMsg = {
        'msg' : answer,
        'conv_id' : conv_id,
        'msg_type' : "assistant",
        'response_from' : 'this response is generated from '+filename2
    }

    botSerializer = MessageSerializer(data = botMsg)
    if botSerializer.is_valid():
        botSerializer.save()
        return Response(botSerializer.data, status=status.HTTP_201_CREATED)
    else:
        print("bot serializer error")
        return Response(botSerializer.error_messages, status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def addSystemPrompt(request):
    serializer = SystemPromptSerializer(data = request.data)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.error_messages, status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def updateSystemPrompt(request, id):
    try:
        prompt = SystemPrompt.objects.get(id=id)
    except SystemPrompt.DoesNotExist:
        return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = SystemPromptSerializer(prompt, data=request.data, partial=True)
    if serializer.is_valid():
            serializer.save()
            return Response(serializer.data, status=status.HTTP_200_OK)
    return Response(status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def getSystemPrompt(request, id):
    try:  
        person = SystemPrompt.objects.get(pk=id) 
    except SystemPrompt.DoesNotExist:
        return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = SystemPromptSerializer(person)
    return Response(serializer.data)

@api_view(['POST'])
def addTemperature(request):
    serializer = LLMTemperatureSerializer(data = request.data)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.error_messages, status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def updateTemp(request, id):
    try:
        temperature = LLMTemperature.objects.get(id=id)
    except LLMTemperature.DoesNotExist:
        return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = LLMTemperatureSerializer(temperature, data=request.data, partial=True)
    if serializer.is_valid():
            serializer.save()
            return Response(serializer.data, status=status.HTTP_200_OK)
    return Response(status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def getTemp(request, id):
    try:  
        person = LLMTemperature.objects.get(pk=id) 
    except LLMTemperature.DoesNotExist:
        return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = LLMTemperatureSerializer(person)
    return Response(serializer.data)

@api_view(['POST'])
def dashBoardData(request):
    # pass
    message_feedback = Message.objects.values('feedback').annotate(count=Count('feedback'))
    message_feedback = {item['feedback']: item['count'] for item in message_feedback} 
    grouped_data = Message.objects.annotate(date=TruncDate('time')).values('date', 'conv_id').distinct()

    result = defaultdict(list)
    for item in grouped_data:  
        result[item['date']].append(item['conv_id'])

    date_conv_id = [{'date': key, 'conv_id': list(set(value))} for key, value in result.items()]
    

    for item in date_conv_id:
        conv_id = item['conv_id']
        convs = Conversation.objects.filter(id__in=conv_id)  # get all convs with those ids
        emails = [conv.email_id for conv in convs]
        emails = list(set(emails))
        item['conv_id'] = len(emails)
        # print(str(conv_id)+"\n")
    # grouped_data = Message.objects.annotate(date=TruncDate('time')).values('date').annotate(count=Count('id'))

    # dashboard_data = {
    #     'liked_count' : liked_count,
    #     'disliked_count': disliked_count,
    #     'neutral_count': neutral_count
    # }
    users_per_day = [{"date": d["date"], "user_count": d["conv_id"]} for d in date_conv_id]

    dashboard_data = {
        "feedback" : message_feedback,
        "userUsage" : users_per_day
    }
    return Response(dashboard_data, status=status.HTTP_202_ACCEPTED)

def deleteAllUserConvs(email_id):
    print('email id received '+email_id)
    conversations = Conversation.objects.filter(email_id=email_id)
    serializer = ConversationSerializer(conversations, many=True)

    # Extract the id field  
    id_list = [item['id'] for item in serializer.data]  

    # Delete the records  
    Message.objects.filter(id__in=id_list).delete() 

    # Delete the records in Conversation  
    conversations.delete()  

    return "deleted conversation history of "+email_id

@api_view(['POST'])
def addLLM(request):
    serializer = LLMSerializer(data=request.data)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) 

@api_view(['POST'])
def getAllLLMs(request):
    llms = LLM.objects.all()
    serializer = LLMSerializer(llms, many=True)
    return Response(serializer.data)

@api_view(['POST'])
def getEnabledLLMs(request):
    enabled_llms = LLM.objects.filter(enabled=True)  
    serializer = LLMSerializer(enabled_llms, many=True)  
    return Response(serializer.data)

@api_view(['POST'])
def updateLLM(request, id):
    try:
        llm = LLM.objects.get(id=id)

    except LLM.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = LLMSerializer(llm, data=request.data, partial=True)

    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_200_OK)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) 

@api_view(['DELETE'])
def deleteLLM(request, id):
    try:
         llm = LLM.objects.get(pk=id) 
    except LLM.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)
    
    # If there are only two records and the other record is not enabled, enable it before deleting the current instance  
    if LLM.objects.count() == 2:  
        other_instance = LLM.objects.exclude(pk=id).first()  
        if not other_instance.enabled:  
            other_instance.enabled = True  
            other_instance.save()
            other_instance.refresh_from_db()  # Ensures that the save operation has completed

    # If there's only one record in the database, return an error and don't delete it  
    elif LLM.objects.count() == 1:  
        return Response({"error": "At least one record must be kept."}, status=400)
    
    # If there's more than one record, proceed with deletion 
    llm.delete()

    return Response({'message': 'LLM deleted successfully'},status=status.HTTP_204_NO_CONTENT)

@api_view(['POST'])
def addContentFilter(request):
    serializer = ContentFilterSerializer(data=request.data)

    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_201_CREATED)
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def updateContentFilter(request, id):
    try:
        filter = ContentFilters.objects.get(id=id)

    except ContentFilters.DoesNotExist:
         return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = ContentFilterSerializer(filter, data=request.data, partial=True)
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data, status=status.HTTP_200_OK)
    return Response(status=status.HTTP_400_BAD_REQUEST)

@api_view(['POST'])
def getContentFilter(request, id):
    try:  
        filter = ContentFilters.objects.get(pk=id) 
    except ContentFilters.DoesNotExist:
        return Response(status=status.HTTP_404_NOT_FOUND)
    
    serializer = ContentFilterSerializer(filter)
    return Response(serializer.data)

@api_view(['POST'])
def dummyApiCall(request):
    from langchain.chat_models import AzureChatOpenAI
    from langchain.schema import HumanMessage
    from openai import AzureOpenAI
    import json
    import os

    openai_api_base = "https://dwspoc.openai.azure.com/"
    openai_api_version = "2024-02-15-preview"
    deployment_name ="GPT4"
    openai_api_key = settings.OPENAI_API_KEY
    openai_api_type="azure"
    client = AzureOpenAI(
                azure_endpoint = openai_api_base, 
                api_key=openai_api_key,  
                api_version=openai_api_version
            )
    query = request.data.get('query', None)
    annonyised_query = anonymize(query)
    response = client.chat.completions.create(
                model="GPT4", # model = "deployment_name".
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": annonyised_query},
                ]
            )
    
    
    print(annonyised_query)
    # answer = llm([HumanMessage(content=annonyised_query)])
    # answer = answer.to_dict()
    deAnonymised_answer = deAnonymize(response.choices[0].message.content)
    return Response({'answer' : deAnonymised_answer})


     
         
